%!TEX root = paper.tex


% \iffalse
% \section{Dependency resolution}
% \label{sec:depres}

% \Red{Delegate this to a future work section}

% There is already a large amount of code published in the Haskell
% ecosystem, and it would be unreasonable to expect everyone to switch
% over to \Backpack{} overnight.  Thus, in our implementation, mixin
% linking operates as a separate pass after traditional dependency
% resolution: where Cabal picks a version and resolves conditional flags
% for every transitively depended upon package\footnote{Versions are per
% package, not component, since versioning is a question of distribution,
% and packages are the unit of distribution.} which respects all of the
% \verb|build-depends| constraints specified by all of the packages.
% Thus, \ccomp{}s are oblivious to dependency resolution:
% they have no \verb|build-depends| and no conditional flags,
% and package names in \verb|include|s have been resolved to
% \cid{}s, which uniquely identify a component after dependency resolution
% has been carried out.

% A full account of dependency resolution in Cabal is out of scope for
% this paper, but there are two important things to say about it:

% \paragraph{Dependency resolution is complex}
% The constraints which the dependency solver must solve can be quite
% complex.  Here is an example using conditional flags:

% \begin{verbatim}
% name: depsolve
% version: 1.0
% flag new-uri
% library
%   if flag(new-uri)
%     build-depends: network-uri >= 2.6, network >= 2.6
%   else
%     build-depends: network-uri < 2.6, network < 2.6
% \end{verbatim}

% Intuitively, \verb|depsolve| accepts all versions of \verb|network|
% and \verb|network-uri|, but requires that if \verb|network-uri| is
% assigned a version greater than or equal to \verb|2.6|, then
% \verb|network| must also be greater than or equal to \verb|2.6|, and
% vice versa.  This constraint is encoded using a \emph{conditional flag}
% named \verb|new-uri|: a flag may be either true or false, and depending
% on the value of a flag, and \verb|build-depends| constraints (and other
% properties) can be conditionalized on flags.

% \paragraph{Dependency resolution is orthogonal to Backpack}
% Mix-in linking does not subsume dependency resolution:
% \verb|build-depends| constraints are a way to ask a computer to resolve
% dependencies, while mix-in linking are a way for a human to manually
% resolve dependencies.  A point of future work is to investigate
% how we could extend the constraints system to let a computer
% automatically perform mix-in linking for unresolved signatures.
% At the very least, a limited scheme where signatures are used to
% replace version ranges would be quite desirable.  However, this
% poses a chicken-and-egg problem for Haskell today: the interface
% provided by a dependency is not well-defined until after dependency
% resolution; so how can we determine if it implements a signature
% in the course of dependency resolution?

% Completely automatic resolution based on signatures
% is probably undesirable: if you have a requirement for a
% cryptographic implementation, you don't want the dependency solver to
% ``solve'' the requirement with a null cipher!
% \fi

\chapter{Evaluation}
\label{sec:evaluation}

Backpack is implemented as a set of patches to GHC and Cabal.
We've tested our implementation in a number of ways:

\paragraph{An alternate package language}  A benefit of having
a separation between mixin linking and typechecking is that it is
a simple matter to swap the frontend language with something else.
To assist in testing Backpack, we implemented a simple alternate
frontend, based off of \OldBackpack{}, which typechecks component
definitions of the form:

\begin{verbatim}
    component p where
        include base
        signature H where
            data T
        module M where
            import H
\end{verbatim}
%
Such inlined module and signature definitions
are extremely handy for test-cases, although
they are not so helpful for libraries with large modules.

\paragraph{Replacing build-depends with signatures}  To show that
\Backpack{} supports real-world ``modularity in the large,'' we took a few
packages in the public Hackage repository and rewrote them to deprecate some of
their \verb|build-depends|
in favor of signatures instead:

\begin{itemize}
    \item We rewrote \texttt{binary-0.8.0.0}\footnote{\smaller\url{https://hackage.haskell.org/package/binary-0.8.0.0}}
          to have signatures
          for \texttt{byte\-string}, \texttt{containers} and \texttt{array},
          demonstrating that GHC's core libraries can be modularized
          over. (23 signatures)

    \item We rewrote \texttt{ghc-simple-0.3}\footnote{\smaller\url{https://hackage.haskell.org/package/ghc-simple-0.3}} to have signatures
          for \texttt{ghc}, demonstrating that the GHC API (a very
          complicated API) can be modularized over. (57 signatures)
\end{itemize}

For example, here is the signature we wrote for \texttt{Data.\allowbreak{}Array.\allowbreak{}IArray}
in \texttt{binary}, exercising many of Haskell's features including
type classes:

\begin{verbatim}
  {-# LANGUAGE ... #-}
  module Data.Array.IArray(
    module Data.Array.IArray,
    module Data.Ix
    ) where

  import Data.Ix

  type role Array nominal representational
  class IArray (a :: * -> * -> *) e
  data Array i e
  instance IArray Array e
  bounds :: (IArray a e) => forall i. Ix i
                         => a i e -> (i, i)
\end{verbatim}
%
Adding signatures to packages was a straightforward (if a little tedious)
process.  One thing we discovered, however, was that the lack of
\emph{recursively dependent signatures} \cite{crary+:recmod-pldi}
(\ie signatures that form an import cycle)
sometimes caused problems when a
dependency was implemented using \texttt{hs-boot} files to implement
recursion.  However, this could be easily worked around by adding
a ``synthetic'' signature which collected all of the mutually dependent
data types together, and then have the real signatures reexport
from this signature;  the synthetic signature is then implemented using
a dummy module.  Here is an example of such a synthetic signature
from \texttt{ghc-simple}'s signatures for GHC:

\begin{verbatim}
  module RecTypes where

  import ConLike  (ConLike)
  import CoAxiom  (Branched, CoAxiom)
  import OccName  (OccName)

  data Id      -- from Id,   imports Name
  data Name    -- from Name, imports Type
  data TyCon   -- from Type
  data TyThing -- from Type, imports Id
      = AnId Id
      | AConLike ConLike
      | ATyCon TyCon
      | ACoAxiom (CoAxiom Branched)
\end{verbatim}
Without this synthetic signature, the signatures for \texttt{Id}, \texttt{Name},
and \texttt{Type} would form a cycle.

\section{Limitations}
\label{sec:limitations}

Some significant tasks remain to complete \Backpack{}.  We discuss
some of the limitations of the current system here.

\section{Metatheory}
\label{sec:metatheory}

We have not rigorously done proofs on \Backpack{}'s metatheory; as such, we can
only conjecture that in the fragment of Haskell without type classes
and type families, successful separate typechecking of components
implies successful linking as well.

One thing that is troublesome about the theorem in \OldBackpack{}, however,
is that it simply is not true for full Haskell.  Specifically,
open type families~\cite{schrijvers+:typefamilies} are inherently non-modular, as they
introduce axioms to Haskell which cannot be hidden by signatures.
Any module system which supports such open type families must either
(1) impose a strict \emph{orphan} constraint, so that declared axioms
in separate modules are guaranteed not to conflict, or (2) allow
for the possibility that linking can fail, even if the components
typechecked separately.

There is a soundness result we can report, however: the soundness of
\emph{compiled} \Backpack{} code reduces to the soundness of GHC
Haskell.  This is because we retypecheck and compile every instantiation
of a component, and thus the compilation process reduces to ordinary
Haskell compilation.  The retypechecking step during compilation is
where things like incompatible open type family axioms are found.
Indeed, it would be possible to skip the typechecking step described in
this paper altogether.

\section{Signature merging}
\label{sec:merging}

In our tour of Backpack, we stated that requirements from multiple
components automatically merge together when they are brought into
scope.  Indeed, we have implemented this; unfortunately, it is unclear
how to formally specify this process without substantially complicating
the typechecking rules, which is why our typechecking semantics
currently nondeterministically guess the ``correct'' requirement type.
The problem is that in our semantics, when we do component
instantiation, it is assumed that you know the module types of all of
the inputs to the component, including the module types of local
requirements.  However, to determine a type of a requirement to merge
in, you need to be able to instantiate a component prior to knowing how
all of its holes are instantiated.

We have not yet found a satisfactory way of formalizing this
algorithmically.  Of course, using the semantics for \OldBackpack{}, the
merged type can be determined; however, to implement \OldBackpack{}
directly would require successively refining the types of modules we
have already typechecked, which is a poor match for a one source file,
one output file compilation model.  It is also possible to assume
that the locally written signature is complete (this is implemented
as a flag) and not attempt to do any merging.  It would be simple to
adjust the rules for this case.
